# abusive-detects-on-chat-system
ğŸ›¡ï¸ Abuse Detection System
Overview

The Abuse Detection module identifies inappropriate, toxic, or harmful language in chat messages. It helps maintain a safe chat environment by monitoring user behavior and applying moderation rules automatically.

ğŸ¯ Key Features

Abusive Word Detection â€“ Detects predefined offensive terms

Toxicity Scoring â€“ Calculates severity based on abusive content

Progressive Warning System â€“ Issues warnings before blocking users

Automatic User Blocking â€“ Blocks repeated offenders

Message Logging â€“ Records abusive messages for review

âš™ï¸ How It Works

User sends a message

System scans message for abusive words

Toxicity score is calculated

Warning issued if abuse detected

User blocked after repeated violations

ğŸ“Š Warning Levels
Warning Level	Action
Warning 1	Notify user
Warning 2	Strong warning
Warning 3	Final warning
Warning 4	ğŸš« User blocked
ğŸ§  Detection Methods
Keyword Matching

Uses predefined abusive word list

Case-insensitive detection

Obfuscation Handling

Detects altered abusive words

Example: 1d10t â†’ idiot

Toxicity Density

Calculates percentage of abusive words

Higher percentage = stronger action

ğŸ’» Example Python Code
abusive_words = ["idiot", "stupid", "hate"]

def detect_abuse(message):
    words = message.lower().split()
    abusive_count = sum(1 for w in words if w in abusive_words)

    if abusive_count > 0:
        print("âš ï¸ Abusive message detected")
    else:
        print("âœ… Clean message")

detect_abuse("You are stupid")

ğŸš¨ Example Output
Input: "You are stupid"
Output: âš ï¸ Abusive message detected

ğŸ”§ Configuration Example
WARNING_LIMIT = 3
BLOCK_LIMIT = 4

ABUSIVE_WORDS = {
    "idiot",
    "stupid",
    "hate"
}

ğŸ“Œ Best Practices

Keep abusive word list updated

Use AI sentiment analysis for accuracy

Log violations for admin review

Combine abuse detection with spam filtering
